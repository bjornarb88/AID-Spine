{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Requirements\n",
    "\n",
    "!pip install pandas==1.1.5 \n",
    "\n",
    "!pip install numpy==1.22.4 \n",
    "\n",
    "!pip install scipy==1.7.3 \n",
    "\n",
    "!pip install scikit-learn==1.1.1 \n",
    "\n",
    "!pip install joblib==1.1.0 \n",
    "\n",
    "!pip install pyyaml==5.4.1 \n",
    "\n",
    "!pip install shap==0.38.1 \n",
    "\n",
    "!pip install matplotlib==3.5.1 \n",
    "\n",
    "!pip install xgboost==1.6.1 \n",
    "\n",
    "!pip install joblib==1.1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers_mi as helper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import joblib\n",
    "\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import shap \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "#Dataset file. If you have multiple datasets DO NOT add the number. It will be added later. \n",
    "#Example if your files are called cluster_mi1, cluster_mi2, etc. just type cluster_mi as the name. \n",
    "data_file = f'data/mi_data/ndipass_swe_mi.csv'\n",
    "\n",
    "\n",
    "#Change this for the number of datasets your MICE procedure created\n",
    "n_datasets = 50\n",
    "\n",
    "#If the output needs imputing change this to True\n",
    "impute_output = False\n",
    "\n",
    "#If you have predetermined clusters for cross validation, this should be true\n",
    "extint_val = False\n",
    "\n",
    "#Name of the output variable you want to predict.\n",
    "target_variable = 'ndipass'\n",
    "\n",
    "#File to output the results\n",
    "output_file       = 'data/results/validation/results_models_validation.csv'\n",
    "\n",
    "threshold = 0.50\n",
    "\n",
    "\n",
    "#Settings files\n",
    "settings_file     = 'settings/settings_val.yml'\n",
    "variable_names    = 'settings/variable_names.yml'\n",
    "sample_file       = 'settings/sample_patients.yml'\n",
    "\n",
    "#Model save\n",
    "model_dump = 'savedmodels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.check_paths() #Check that all the folders needed are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings file with models and their hyperparameters\n",
    "with open(settings_file, \"r\") as stream:\n",
    "    settings = yaml.load(stream, Loader=SafeLoader)\n",
    "\n",
    "#Variable names and labels for graphs\n",
    "with open(variable_names, \"r\") as stream:\n",
    "    var_names = yaml.load(stream, Loader=SafeLoader)\n",
    "    \n",
    "#Example patients to check for variable influence\n",
    "with open(sample_file, 'r') as stream:\n",
    "    samples = yaml.load(stream, Loader = SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results, test_results = helper.get_results_dicts(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in range(n_datasets):\n",
    "    \n",
    "    #Getting the dataset for this run\n",
    "    if n_datasets>1:\n",
    "        dataset = data_file[:-4]\n",
    "        dataset = dataset + f'{d+1}.csv'\n",
    "    else:\n",
    "        dataset = data_file\n",
    "    df, x, y, clusters_idx = helper.get_data(dataset, target_variable, impute_output = impute_output, extint_val = extint_val)\n",
    "\n",
    "    #Getting the sample patients\n",
    "    sample_x = pd.DataFrame(columns = x.columns)\n",
    "\n",
    "    for patient, values in samples.items():\n",
    "        sample_x = sample_x.append(values, ignore_index = True)\n",
    "\n",
    "\n",
    "    for model_name, attr in settings['models'].items():\n",
    "\n",
    "        print(model_name)\n",
    "        full_model = joblib.load(model_dump + model_name + '_cv.joblib')\n",
    "        pipe = full_model['preprocessor']\n",
    "        model = full_model['predictor']\n",
    "        proba_df_test = pd.DataFrame(columns = ['cluster','Test', 'Predicted', 'Proba'])\n",
    "\n",
    "        numerical_features, categorical_features = helper.feature_discrimination(x,settings)\n",
    "\n",
    "        sample_m = sample_x[x.columns].copy()\n",
    "\n",
    "        #Changing the order of features to match it to the ones after the pipeline - This is done for SHAP purposes\n",
    "        x_ = x.loc[:, numerical_features.to_list()+categorical_features.to_list()].copy()\n",
    "        sample_m = sample_m.loc[:, numerical_features.to_list()+categorical_features.to_list()]\n",
    "\n",
    "        #List for example patients\n",
    "        y_sample_test = []\n",
    "\n",
    "        #Divide the datasets into train-test with respect to pre-defined clusters\n",
    "        for cluster_name in settings['clusters']:\n",
    "            n_cluster = settings['clusters'][cluster_name]\n",
    "            print(f'Testing Cluster N{n_cluster}, {cluster_name}')\n",
    "\n",
    "            x_test  = x_[clusters_idx == n_cluster].copy()\n",
    "            y_test  =  y[clusters_idx == n_cluster].copy()\n",
    "\n",
    "            test_results[model_name][cluster_name]['shap_df'].append(x_test)\n",
    "\n",
    "            x_test  = pipe.transform(x_test)\n",
    "            sample_model = pipe.transform(sample_m)\n",
    "\n",
    "            features = list(numerical_features) + list(pipe['preprocessor'].transformers_[1][1]['one-hot'].get_feature_names_out(categorical_features))\n",
    "            x_test = pd.DataFrame(x_test, columns = features)\n",
    "            sample_model = pd.DataFrame(sample_model, columns = features)\n",
    "\n",
    "            y_proba_test  = model.predict_proba(x_test)[:,1]    \n",
    "\n",
    "            y_sample_test.append(model.predict_proba(sample_model)[:,1])\n",
    "\n",
    "            \n",
    "            y_pred_test  = helper.get_prediction(y_test, y_proba_test, threshold)\n",
    "            \n",
    "            #Compute SHAP if needed - Only for first dataset\n",
    "            if (settings['models'][model_name]['shap'] == True) & (d == 0):\n",
    "                print(\"Getting SHAP values\")\n",
    "                shap_type = settings['models'][model_name]['shap_type']\n",
    "                test_results[model_name][cluster_name] = helper.compute_SHAP(model, \n",
    "                                                                             x_test,\n",
    "                                                                             test_results[model_name][cluster_name],\n",
    "                                                                             categorical_features,\n",
    "                                                                             shap_type\n",
    "                                                                            )\n",
    "\n",
    "            test_results[model_name][cluster_name] = helper.get_ROC_cluster_mi(model, \n",
    "                                                                               x_test, \n",
    "                                                                               y_test, \n",
    "                                                                               test_results, \n",
    "                                                                               model_name, \n",
    "                                                                               cluster_name)\n",
    "\n",
    "            test_results[model_name][cluster_name] = helper.get_calibration(y_test,\n",
    "                                                                            y_proba_test, \n",
    "                                                                            test_results,\n",
    "                                                                            model_name,\n",
    "                                                                            cluster_name)\n",
    "\n",
    "            score = ''\n",
    "            for score_name, attr in settings['scoring_test'].items():\n",
    "                score = helper.get_scoring(score_name, attr)\n",
    "                score_value = eval(score)\n",
    "                test_results[model_name][cluster_name][score_name].append(score_value)\n",
    "\n",
    "                SE = helper.get_SE(score_value, y_test)\n",
    "                test_results[model_name][cluster_name][score_name + '_SE'].append(SE)\n",
    "\n",
    "                CI = helper.get_CI(SE, y_test.shape[0])\n",
    "                test_results[model_name][cluster_name][score_name + '_CI'].append(CI)\n",
    "\n",
    "\n",
    "            proba_df = pd.DataFrame(columns = ['cluster','Test', 'Predicted', 'Proba'])\n",
    "            proba_df['Test']      = y_test\n",
    "            proba_df['Predicted'] = y_pred_test\n",
    "            proba_df['Proba']     = y_proba_test\n",
    "            proba_df['cluster']   = clusters_idx\n",
    "            test_results[model_name][cluster_name]['Proba_df'].append(proba_df)\n",
    "\n",
    "            proba_df_test = pd.concat([proba_df_test, proba_df])\n",
    "\n",
    "\n",
    "        sample_x[f\"{model_name} \"] = np.mean(y_sample_test, axis = 0)\n",
    "\n",
    "        proba_df_test.to_csv(f'data/results/validation/{model_name}_cluster_mi{d+1}_Proba_Test.csv', sep=';', index=False)\n",
    "    \n",
    "sample_x.to_csv('data/results/validation/Samples.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_results(tr_res,te_res, settings_):\n",
    "    tr_results_merged, te_results_merged = helper.get_results_dicts(settings_)\n",
    "    \n",
    "    for model_name in settings_['models']:\n",
    "        for cluster_name in settings_['clusters']:\n",
    "            for score_name in settings_['scoring_train']:\n",
    "\n",
    "                scores = te_res[model_name][cluster_name][score_name]\n",
    "                standard_errors = te_res[model_name][cluster_name][score_name + '_SE']\n",
    "                conf_int = te_res[model_name][cluster_name][score_name + '_CI']\n",
    "                merged_score, merged_SE, CI = helper.apply_rubin_rule(scores, standard_errors, conf_int)\n",
    "\n",
    "                te_results_merged[model_name][cluster_name][score_name].append(merged_score)\n",
    "                te_results_merged[model_name][cluster_name][score_name + '_SE'].append(merged_SE)\n",
    "                te_results_merged[model_name][cluster_name][score_name + '_CI'].append(CI)\n",
    "                \n",
    "            for item in ['Intercept','Slope']:\n",
    "                \n",
    "                scores = te_res[model_name][cluster_name][item]\n",
    "                standard_errors = te_res[model_name][cluster_name][item + '_SE']\n",
    "                conf_int = te_res[model_name][cluster_name][item + '_CI']\n",
    "                merged_score, merged_SE, CI = helper.apply_rubin_rule(scores, standard_errors, conf_int)\n",
    "\n",
    "                te_results_merged[model_name][cluster_name][item].append(merged_score)\n",
    "                te_results_merged[model_name][cluster_name][item + '_SE'].append(merged_SE)\n",
    "                te_results_merged[model_name][cluster_name][item + '_CI'].append(CI)\n",
    "\n",
    "            \n",
    "\n",
    "            te_results_merged[model_name][cluster_name]['Proba_df'].append(pd.DataFrame(np.mean(te_res[model_name][cluster_name]['Proba_df'], axis=0), \n",
    "                 index = te_res[model_name][cluster_name]['Proba_df'][0].index,\n",
    "                 columns = te_res[model_name][cluster_name]['Proba_df'][0].columns))\n",
    "\n",
    "            \n",
    "            if settings_['models'][model_name]['shap']==True:\n",
    "                shap_list = []\n",
    "                \n",
    "                for fold in range(len(te_res[model_name][cluster_name]['shap_values'])):\n",
    "                    shap_list.append(te_res[model_name][cluster_name]['shap_values'][fold].values)\n",
    "                    \n",
    "                te_results_merged[model_name][cluster_name]['shap_values'].append(np.mean(shap_list, axis=0))\n",
    "\n",
    "                te_results_merged[model_name][cluster_name]['shap_df'].append(pd.DataFrame(np.mean(te_res[model_name][cluster_name]['shap_df'], axis=0), \n",
    "                     index = te_res[model_name][cluster_name]['shap_df'][0].index,\n",
    "                     columns = te_res[model_name][cluster_name]['shap_df'][0].columns))\n",
    "                te_results_merged[model_name][cluster_name]['shap_explainer'].append(te_res[model_name][cluster_name]['shap_explainer'][0])\n",
    "    return tr_results_merged, te_results_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the results from the n-datasets\n",
    "train_results_merged, test_results_merged = merge_results(train_results, test_results, settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reform = {(outerKey, innerKey): values for outerKey, innerDict in test_results_merged.items() for innerKey, values in innerDict.items()}\n",
    "rows = pd.MultiIndex.from_tuples(list(reform.keys()), names = ['Model','Region'])\n",
    "\n",
    "to_keep = ['roc_auc','Intercept','Slope','precision','NPV']\n",
    "columns = []\n",
    "for item in to_keep:\n",
    "    columns.append(item)\n",
    "    columns.append(item + '_CI')\n",
    "    columns.append(item + '_SE')\n",
    "\n",
    "\n",
    "train_results_df = pd.DataFrame(columns = columns,\n",
    "                                index = rows)\n",
    "test_results_df = pd.DataFrame(columns = columns,\n",
    "                               index = rows)\n",
    "\n",
    "for model_name in settings['models']:\n",
    "    for cluster_name in settings['clusters']:\n",
    "        for item in to_keep:\n",
    "            test_results_df.loc[(model_name,cluster_name),[item]] = round(test_results_merged[model_name][cluster_name][item][0],4)\n",
    "\n",
    "            test_results_df.loc[(model_name,cluster_name),[item + '_SE']] = round(test_results_merged[model_name][cluster_name][item + '_SE'][0],4)\n",
    "\n",
    "            test_results_df.loc[(model_name,cluster_name),[item + '_CI']] = round(test_results_merged[model_name][cluster_name][item + '_CI'][0],4)\n",
    "\n",
    "    test_results_df.loc[(model_name,'Overall'),:] = round(test_results_df.loc[(model_name)].mean(),4)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, attr in settings['models'].items():  \n",
    "    #Comment this to avoid SHAP\n",
    "    print(model_name)\n",
    "    if settings['models'][model_name]['shap'] == True:\n",
    "        print('Getting SHAP Plots')\n",
    "        test_results[model_name] = helper.get_SHAP_plot_validation(test_results, model_name, var_names,settings, cols = 3)\n",
    "    print('Getting ROC Plots')\n",
    "    test_results_merged[model_name] = helper.get_ROC_plot_validation(test_results_merged, test_results, model_name, settings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([train_results_df, test_results_df], keys = ['Train', 'Test'], axis = 0)\n",
    "results_df = results_df.reset_index(level= [2])\n",
    "results_df.columns.values[0] = 'Region'\n",
    "\n",
    "results_df = results_df.reset_index(level= [1])\n",
    "results_df.columns.values[0] = 'Model'\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(output_file, sep =';')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

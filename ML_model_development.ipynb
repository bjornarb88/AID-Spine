{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Requirements\n",
    "\n",
    "!pip install pandas==1.1.5\n",
    "!pip install numpy==1.22.4\n",
    "!pip install scipy==1.7.3\n",
    "!pip install scikit-learn==1.1.1\n",
    "!pip install joblib==1.1.0\n",
    "!pip install pyyaml==5.4.1\n",
    "!pip install shap==0.38.1\n",
    "!pip install matplotlib==3.5.1\n",
    "!pip install xgboost==1.6.1\n",
    "!pip install joblib==1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To run this code:\n",
    "1) Have a \"data\" folder with the dataset stored.\n",
    "\n",
    "2) Have a \"settings\" folder with:\n",
    "\n",
    "    a) A YAML file with the model, hyperparameters, list of numerical variables\n",
    "    b) A YAML file with a list of the variable names, labels and descriptions (This is how you would like them to appear in a graph).\n",
    "    c) A YAML file with two or more 'sample' patients. \n",
    "    \n",
    "3) Check for names and parameters in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers_mi as helper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import joblib\n",
    "\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import shap \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT INFORMATION\n",
    "\n",
    "If you performed **MULTIPLE IMPUTATION** (MICE procedure):<br>\n",
    "1. Keep the name without numbers in the 'data_file'. Numbers will be added later.<br>\n",
    "&emsp;Example:  MICE was performed and it produced 50 files called data1.csv, data2.csv, etc. The 'data_file' should only be called data.csv.  <br>\n",
    "2. Change the number of 'n_datasets' to the number of data files produced by MICE.<br> \n",
    "3. This code does NOT perform the MICE procedure. If your data is incomplete it will be imputed using IterativeImputer. <br>\n",
    "    \n",
    "If you want to perform **EXTERNAL-INTERNAL VALIDATION**:<br>\n",
    "1. Change 'extint_val to True. <br>\n",
    "2. Your dataset must have a 'cluster' variable with the samples identified to which cluster they belong to. Use numbers. <br>\n",
    "3. In the 'settings.yaml' file, under 'clusters', name your clusters and add the identification number to them. This will allow for the clusters to be named. <br>\n",
    "    \n",
    "If you dont want to perform **EXTERNAL-INTERNAL VALIDATION**:<br>\n",
    "1. Change 'extint_val' to False<br>\n",
    "2. In the 'settings.yaml' file, under 'clusters', name your clusters Fold 1: 1, Fold 2: 2 and so on until Fold 5.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "#Dataset file. If you have multiple datasets DO NOT add the number. It will be added later. \n",
    "#Example if your files are called cluster_mi1, cluster_mi2, etc. just type cluster_mi as the name. \n",
    "data_file = f'data/mi_data/ndipass_period1_mi.csv'\n",
    "\n",
    "#Change this value to the name of the id variable if you have any\n",
    "id_var = 'id'\n",
    "\n",
    "#Change this for the number of datasets your MICE procedure created\n",
    "n_datasets = 50\n",
    "\n",
    "#If the outcome needs imputing change this to True\n",
    "impute_output = False\n",
    "\n",
    "#If you have predetermined clusters for cross validation, this should be True\n",
    "extint_val = False\n",
    "\n",
    "#Name of the output variable you want to predict.\n",
    "target_variable = 'ndipass'\n",
    "\n",
    "#File to output the results\n",
    "output_file       = 'data/results/results_models_development.csv'\n",
    "\n",
    "#Pickle files to store results\n",
    "train_save_file   = 'data/results/train_save_file.txt'\n",
    "test_save_file    = 'data/results/test_save_file.txt'\n",
    "\n",
    "train_save_file_merged   = 'data/results/train_save_file_merged.txt'\n",
    "test_save_file_merged    = 'data/results/test_save_file_merged.txt'\n",
    "\n",
    "#Settings files\n",
    "settings_file     = 'settings/settings.yml'\n",
    "sample_file       = 'settings/sample_patients.yml'\n",
    "variable_names    = 'settings/variable_names.yml'\n",
    "\n",
    "#Model save\n",
    "model_dump = 'savedmodels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.check_paths() #Check that all the folders needed are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Settings file with models and their hyperparameters\n",
    "with open(settings_file, \"r\") as stream:\n",
    "    settings = yaml.load(stream, Loader=SafeLoader)\n",
    "\n",
    "#Variable names and labels for graphs\n",
    "with open(variable_names, \"r\") as stream:\n",
    "    var_names = yaml.load(stream, Loader=SafeLoader)\n",
    "    \n",
    "#Example patients\n",
    "with open(sample_file, 'r') as stream:\n",
    "    samples = yaml.load(stream, Loader = SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results, test_results = helper.get_results_dicts(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for d in range(n_datasets):\n",
    "    \n",
    "    #Getting the dataset for this run\n",
    "    if n_datasets>1:\n",
    "        dataset = data_file[:-4]\n",
    "        dataset = dataset + f'{d+1}.csv'\n",
    "    else:\n",
    "        dataset = data_file\n",
    "    df, x, y, clusters_idx = helper.get_data(dataset, target_variable, impute_output = impute_output, extint_val = extint_val, id_var=id_var)\n",
    "    \n",
    "    #Getting the sample patients\n",
    "    sample_x = pd.DataFrame(columns = x.columns)\n",
    "\n",
    "    for patient, values in samples.items():\n",
    "        sample_x = sample_x.append(values, ignore_index = True)\n",
    "        \n",
    "        \n",
    "    print(f\"Running dataset N{d+1}\")\n",
    "    for model_name, attr in settings['models'].items():\n",
    "        best_model = None\n",
    "        best_pipe = None\n",
    "        best_auc = 0\n",
    "        best_thresh = 0\n",
    "\n",
    "\n",
    "        print(model_name)\n",
    "        proba_df_train = pd.DataFrame(columns = ['cluster','Train', 'Predicted', 'Proba'])\n",
    "        proba_df_test = pd.DataFrame(columns = ['cluster','Test', 'Predicted', 'Proba'])\n",
    "        \n",
    "        numerical_features, categorical_features = helper.feature_discrimination(x,settings)\n",
    "\n",
    "        sample_m = sample_x[x.columns].copy()\n",
    "\n",
    "        #Changing the order of features to match it to the ones after the pipeline - This is done for SHAP purposes\n",
    "        x_ = x.loc[:, numerical_features.to_list()+categorical_features.to_list()].copy()\n",
    "        sample_m = sample_m.loc[:, numerical_features.to_list()+categorical_features.to_list()]\n",
    "\n",
    "        #Declaring the pipeline\n",
    "        numeric_pipeline = Pipeline(\n",
    "            steps = [\n",
    "                (\"impute\", IterativeImputer(sample_posterior = True, random_state = 0)),\n",
    "                (\"scale\", MinMaxScaler()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        categorical_pipeline = Pipeline(\n",
    "            steps = [\n",
    "                (\"impute\", SimpleImputer(strategy = 'most_frequent')),\n",
    "                (\"one-hot\", OneHotEncoder(handle_unknown = 'ignore', sparse = False, ))\n",
    "            ]\n",
    "        )\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers = [\n",
    "                (\"Number\", numeric_pipeline, numerical_features),\n",
    "                (\"Category\", categorical_pipeline, categorical_features)\n",
    "\n",
    "            ],\n",
    "            remainder = 'passthrough')\n",
    "\n",
    "        pipe = Pipeline(\n",
    "            steps = [('preprocessor', preprocessor)])\n",
    "\n",
    "        #Declaring the model\n",
    "        model_string = helper.create_model(model_name, attr['param'])\n",
    "\n",
    "        #List for example patients\n",
    "        y_sample_test = []\n",
    "\n",
    "        #Divide the datasets into train-test with respect to pre-defined clusters\n",
    "        for cluster_name in settings['clusters']:\n",
    "            n_cluster = settings['clusters'][cluster_name]\n",
    "            print(f'Running Cluster N{n_cluster}, {cluster_name}')\n",
    "\n",
    "            x_train = x_[clusters_idx != n_cluster].copy()\n",
    "            y_train =  y[clusters_idx != n_cluster].copy()\n",
    "            x_test  = x_[clusters_idx == n_cluster].copy()\n",
    "            y_test  =  y[clusters_idx == n_cluster].copy()\n",
    "            \n",
    "            test_results[model_name][cluster_name]['shap_df'].append(x_test)\n",
    "\n",
    "            x_train = pipe.fit_transform(x_train)\n",
    "            x_test  = pipe.transform(x_test)\n",
    "            sample_model = pipe.transform(sample_m)\n",
    "            \n",
    "            features = list(numerical_features) + list(pipe['preprocessor'].transformers_[1][1]['one-hot'].get_feature_names_out(categorical_features))\n",
    "            x_train= pd.DataFrame(x_train, columns = features)\n",
    "            x_test = pd.DataFrame(x_test, columns = features)\n",
    "            sample_model = pd.DataFrame(sample_model, columns = features)\n",
    "            \n",
    "            #Instantiate the model\n",
    "            model = eval(model_string)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            #Compute SHAP if needed\n",
    "            if (settings['models'][model_name]['shap'] == True) & (d == 0):\n",
    "                print(\"Getting SHAP values\")\n",
    "                shap_type = settings['models'][model_name]['shap_type']\n",
    "                test_results[model_name][cluster_name] = helper.compute_SHAP(model, \n",
    "                                                                             x_test,\n",
    "                                                                             test_results[model_name][cluster_name],\n",
    "                                                                             categorical_features,\n",
    "                                                                             shap_type\n",
    "                                                                            )\n",
    "\n",
    "\n",
    "            y_proba_train = model.predict_proba(x_train)[:,1]\n",
    "            y_proba_test  = model.predict_proba(x_test)[:,1]    \n",
    "\n",
    "            y_sample_test.append(model.predict_proba(sample_model)[:,1])\n",
    "\n",
    "            #Getting best threshold based on ROC curve \n",
    "            #Or calculate performance estimates based on predicted probabities\n",
    "            thresh = helper.get_threshold(y_train, y_proba_train)\n",
    "            y_pred_train = helper.get_prediction(y_train, y_proba_train, thresh)\n",
    "            y_pred_test  = helper.get_prediction(y_test, y_proba_test, thresh)\n",
    "            \n",
    "            test_results[model_name][cluster_name] = helper.get_ROC_cluster_mi(model, \n",
    "                                                                               x_test, \n",
    "                                                                               y_test, \n",
    "                                                                               test_results, \n",
    "                                                                               model_name, \n",
    "                                                                               cluster_name)\n",
    "\n",
    "            test_results[model_name][cluster_name] = helper.get_calibration(y_test,\n",
    "                                                                            y_proba_test, \n",
    "                                                                            test_results,\n",
    "                                                                            model_name,\n",
    "                                                                            cluster_name)\n",
    "            \n",
    "            train_results[model_name][cluster_name] = helper.get_calibration(y_train,\n",
    "                                                                             y_proba_train,\n",
    "                                                                             train_results,\n",
    "                                                                             model_name,\n",
    "                                                                             cluster_name)\n",
    "            \n",
    "            score = ''\n",
    "            for score_name, attr in settings['scoring_train'].items():\n",
    "                score = helper.get_scoring(score_name, attr)\n",
    "                score_value = eval(score)\n",
    "                train_results[model_name][cluster_name][score_name].append(score_value)\n",
    "\n",
    "                \n",
    "                SE = helper.get_SE(score_value, y_train)\n",
    "                train_results[model_name][cluster_name][score_name + '_SE'].append(SE)\n",
    "                \n",
    "                CI = helper.get_CI(SE, y_train.shape[0])\n",
    "                train_results[model_name][cluster_name][score_name + '_CI'].append(CI)\n",
    "\n",
    "            score = ''\n",
    "            for score_name, attr in settings['scoring_test'].items():\n",
    "                score = helper.get_scoring(score_name, attr)\n",
    "                score_value = eval(score)\n",
    "                test_results[model_name][cluster_name][score_name].append(score_value)\n",
    "\n",
    "                SE = helper.get_SE(score_value, y_test)\n",
    "                test_results[model_name][cluster_name][score_name + '_SE'].append(SE)\n",
    "                \n",
    "                CI = helper.get_CI(SE, y_test.shape[0])\n",
    "                test_results[model_name][cluster_name][score_name + '_CI'].append(CI)\n",
    "                \n",
    "            if (settings['models'][model_name]['save'] == True) & (d == 0):\n",
    "                current_auc = roc_auc_score(y_test,y_proba_test)\n",
    "                if best_auc == 0:\n",
    "                    best_thresh = thresh\n",
    "                    best_auc = current_auc\n",
    "                    best_model = model\n",
    "                    best_pipe = pipe\n",
    "                elif best_auc< current_auc:\n",
    "                    best_auc = current_auc\n",
    "                    best_model = model\n",
    "                    best_pipe = pipe\n",
    "                    best_thresh = thresh\n",
    "                    \n",
    "\n",
    "            proba_df = pd.DataFrame(columns = ['cluster','Train', 'Predicted', 'Proba'])\n",
    "            proba_df['Train']     = y_train\n",
    "            proba_df['Predicted'] = y_pred_train\n",
    "            proba_df['Proba']     = y_proba_train\n",
    "            proba_df['cluster']   = clusters_idx\n",
    "#             proba_df.to_csv(f'data/Probabilities output/{model_name}_mi{d+1}_{cluster_name}_Train.csv', sep=';', index=False)\n",
    "            train_results[model_name][cluster_name]['Proba_df'].append(proba_df)\n",
    "            \n",
    "            proba_df_train = pd.concat([proba_df_train, proba_df])\n",
    "    \n",
    "            proba_df = pd.DataFrame(columns = ['cluster','Test', 'Predicted', 'Proba'])\n",
    "            proba_df['Test']      = y_test\n",
    "            proba_df['Predicted'] = y_pred_test\n",
    "            proba_df['Proba']     = y_proba_test\n",
    "            proba_df['cluster']   = clusters_idx\n",
    "#             proba_df.to_csv(f'data/Probabilities output/{model_name}_mi{d+1}_{cluster_name}_Test.csv', sep=';', index=False)\n",
    "            test_results[model_name][cluster_name]['Proba_df'].append(proba_df)\n",
    "            \n",
    "            proba_df_test = pd.concat([proba_df_test, proba_df])\n",
    "\n",
    "        if (settings['models'][model_name]['save'] == True) & (d == 0):\n",
    "            full_model = Pipeline(\n",
    "                steps = [('preprocessor', best_pipe),\n",
    "                         ('predictor', best_model)])\n",
    "            joblib.dump(full_model, str(model_dump + model_name + '_cv.joblib'))\n",
    "            print('Best threshold is: ', best_thresh)\n",
    "            \n",
    "        sample_x[f\"{model_name} \"] = np.mean(y_sample_test, axis = 0)\n",
    "        \n",
    "#         proba_df_train.to_csv(f'data/Probabilities output/{model_name}_cluster_mi{d+1}_Proba_Train.csv', sep=';', index=False)\n",
    "        proba_df_test.to_csv(f'data/Probabilities output/{model_name}_cluster_mi{d+1}_Proba_Test.csv', sep=';', index=False)\n",
    "    \n",
    "sample_x.to_csv('data/Samples.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = eval(str(shap_type + '(model = model)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Merging the results from the n-datasets\n",
    "train_results_merged, test_results_merged = helper.merge_results(train_results, test_results, settings)\n",
    "\n",
    "helper.save_results(train_save_file_merged, train_results_merged)\n",
    "helper.save_results(test_save_file_merged,  test_results_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reform = {(outerKey, innerKey): values for outerKey, innerDict in test_results_merged.items() for innerKey, values in innerDict.items()}\n",
    "rows = pd.MultiIndex.from_tuples(list(reform.keys()), names = ['Model','Region'])\n",
    "\n",
    "to_keep = ['roc_auc','Intercept','Slope','precision','NPV']\n",
    "columns = []\n",
    "for item in to_keep:\n",
    "    columns.append(item)\n",
    "    columns.append(item + '_CI')\n",
    "    columns.append(item + '_SE')\n",
    "\n",
    "\n",
    "train_results_df = pd.DataFrame(columns = columns,\n",
    "                                index = rows)\n",
    "test_results_df = pd.DataFrame(columns = columns,\n",
    "                               index = rows)\n",
    "\n",
    "for model_name in settings['models']:\n",
    "    for cluster_name in settings['clusters']:\n",
    "        for item in to_keep:\n",
    "            train_results_df.loc[(model_name,cluster_name),[item]] = round(train_results_merged[model_name][cluster_name][item][0],4)\n",
    "            test_results_df.loc[(model_name,cluster_name),[item]] = round(test_results_merged[model_name][cluster_name][item][0],4)\n",
    "\n",
    "            train_results_df.loc[(model_name,cluster_name),[item + '_SE']] = round(train_results_merged[model_name][cluster_name][item + '_SE'][0],4)\n",
    "            test_results_df.loc[(model_name,cluster_name),[item + '_SE']] = round(test_results_merged[model_name][cluster_name][item + '_SE'][0],4)\n",
    "\n",
    "            train_results_df.loc[(model_name,cluster_name),[item + '_CI']] = round(train_results_merged[model_name][cluster_name][item + '_CI'][0],4)\n",
    "            test_results_df.loc[(model_name,cluster_name),[item + '_CI']] = round(test_results_merged[model_name][cluster_name][item + '_CI'][0],4)\n",
    "\n",
    "    train_results_df.loc[(model_name,'Overall'),:] = round(train_results_df.loc[(model_name)].mean(),4)\n",
    "    test_results_df.loc[(model_name,'Overall'),:] = round(test_results_df.loc[(model_name)].mean(),4)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, attr in settings['models'].items():  \n",
    "    #Comment this to avoid SHAP\n",
    "    print(model_name)\n",
    "    if settings['models'][model_name]['shap'] == True:\n",
    "        print('Getting SHAP Plots')\n",
    "#         test_results_merged[model_name] = helper.get_SHAP_plot_cluster_mi_merged(test_results_merged, model_name, var_names,settings, cols = 3)\n",
    "        test_results[model_name] = helper.get_SHAP_plot_cluster_mi(test_results, model_name, var_names,settings, cols = 3)\n",
    "    print('Getting ROC Plots')\n",
    "    test_results_merged[model_name] = helper.get_ROC_plot_cluster(test_results_merged, test_results, model_name, settings)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([train_results_df, test_results_df], keys = ['Train', 'Test'], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.reset_index(level= [2])\n",
    "results_df.columns.values[0] = 'Region'\n",
    "\n",
    "results_df = results_df.reset_index(level= [1])\n",
    "results_df.columns.values[0] = 'Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(output_file, sep =';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
